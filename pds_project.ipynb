{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1638305626047,"user":{"displayName":"Ting-Wei Chiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZPBQZmt8dwjMijV3rWJvOCNSVpxTjtvSeHYZw=s64","userId":"04402508495486442280"},"user_tz":300},"id":"RgKYDkHzF-Ip"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","def openpickle(filename):\n","    with open(filename, \"rb\") as readfile:\n","        loaded = pickle.load(readfile)\n","    return loaded"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":142,"status":"ok","timestamp":1638305653661,"user":{"displayName":"Ting-Wei Chiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZPBQZmt8dwjMijV3rWJvOCNSVpxTjtvSeHYZw=s64","userId":"04402508495486442280"},"user_tz":300},"id":"zf-_wjWFF-It"},"outputs":[],"source":["train_pricing_decisions = pd.read_csv('train_prices_decisions.csv')\n","train_covariate = openpickle('train_covariate')\n","train_noisy_embedding = openpickle('train_noisy_embedding')\n","test_covariate = openpickle('test_covariate')\n","test_noisy_embedding = openpickle('test_noisy_embedding')\n","item0_embedding = openpickle('item0embedding')\n","item1_embedding = openpickle('item1embedding')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftOi4BDgKWvA"},"outputs":[],"source":["from sklearn.neighbors import NearestNeighbors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zIUKLtrPNqwZ"},"outputs":[],"source":["item_vectors = np.array([item0_embedding, item1_embedding])\n","train_pricing_decisions = train_pricing_decisions.set_index('user_index')\n","price_pair = train_pricing_decisions.drop(columns=[\"item_bought\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Iv_R11uyQXn"},"outputs":[],"source":["existing_train_idx = list(train_noisy_embedding.index)\n","existing_train_covariate = train_covariate.loc[existing_train_idx]\n","existing_train_embedding = train_noisy_embedding.loc[existing_train_idx]\n","existing_train_embedding.columns = existing_train_embedding.columns.astype(str)\n","\n","existing_test_idx = list(test_noisy_embedding.index)\n","existing_test_covariate = test_covariate.loc[existing_test_idx]\n","existing_test_embedding = test_noisy_embedding.loc[existing_test_idx]\n","\n","existing_covariate = pd.concat([existing_train_covariate, existing_test_covariate])\n","existing_embedding = pd.concat([existing_train_embedding, existing_test_embedding], axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EvHPNHQ_0m_m"},"outputs":[],"source":["new_train_idx = [u for u in list(train_covariate.index) if u not in existing_train_idx]\n","new_train_covariate = train_covariate.loc[new_train_idx]\n","\n","new_test_idx = [u for u in list(test_covariate.index) if u not in existing_test_idx]\n","new_test_covariate = test_covariate.loc[new_test_idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_std2swrz-yh"},"outputs":[],"source":["# train KNN to get new user vectors\n","N_NEIGHBORS = 5\n","neigh = NearestNeighbors(n_neighbors = N_NEIGHBORS)\n","neigh.fit(existing_covariate)\n","\n","neighbor_ids = neigh.kneighbors(new_train_covariate, return_distance=False)\n","for i in range(len(new_train_idx)):\n","  curr_embedding = list(existing_embedding.iloc[neighbor_ids[i]].mean(axis=0))\n","  train_noisy_embedding.loc[new_train_idx[i]] = curr_embedding\n","\n","neighbor_ids = neigh.kneighbors(new_test_covariate, return_distance=False)\n","for i in range(len(new_test_idx)):\n","  curr_embedding = list(existing_embedding.iloc[neighbor_ids[i]].mean(axis=0))\n","  test_noisy_embedding.loc[new_test_idx[i]] = curr_embedding\n","\n","train_noisy_embedding = train_noisy_embedding.sort_index()\n","test_noisy_embedding = test_noisy_embedding.sort_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5hMiD2acCrB"},"outputs":[],"source":["X = train_covariate.join(train_noisy_embedding @ item_vectors.T).join(price_pair)\n","X.columns = X.columns.astype(str)\n","X_test = test_covariate.join(test_noisy_embedding @ item_vectors.T)\n","X_test.columns = X_test.columns.astype(str)\n","y = train_pricing_decisions['item_bought']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1638296873032,"user":{"displayName":"Ting-Wei Chiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZPBQZmt8dwjMijV3rWJvOCNSVpxTjtvSeHYZw=s64","userId":"04402508495486442280"},"user_tz":300},"id":"ijsdOR7rtoOq","outputId":"9c91417a-2fab-4154-a995-ad0f3e38d1d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["(14000, 7)\n"]}],"source":["X_train, y_train = X, y\n","print(X_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qAQ5yW511VJ"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegressionCV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrMreIAtDUYa"},"outputs":[],"source":["clf = LogisticRegressionCV(multi_class=\"multinomial\", max_iter=1000).fit(X_train.values, y_train.values)"]},{"cell_type":"markdown","metadata":{"id":"Wuxi4eY3GD3P"},"source":["Revenue-maximizing prices using gradient descent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAL4YeUviZ8m"},"outputs":[],"source":["def get_gradient_direction(min0, max0, min1, max1, curr_df):\n","  res_0, res_1, res_revenue = 0, 0, 0\n","  for p0 in [min0, max0]:\n","    for p1 in [min1, max1]:\n","      curr_revenue = get_curr_revenue(p0, p1, curr_df)\n","      if curr_revenue > res_revenue:\n","        res_0 = p0\n","        res_1 = p1\n","        res_revenue = curr_revenue\n","  return res_0, res_1, res_revenue\n","\n","def get_curr_revenue(p0, p1, curr_df):\n","  curr_df['price_item_0'] = p0\n","  curr_df['price_item_1'] = p1\n","  pred = clf.predict_proba(np.array(curr_df).reshape(1, -1))\n","  curr_revenue = p0 * pred[0][1] + p1 * pred[0][2]\n","  return curr_revenue"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":584674,"status":"ok","timestamp":1638299677785,"user":{"displayName":"Ting-Wei Chiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZPBQZmt8dwjMijV3rWJvOCNSVpxTjtvSeHYZw=s64","userId":"04402508495486442280"},"user_tz":300},"id":"m2vhi35ggWha","outputId":"fbd7d6a8-8e6b-49da-bef8-2dfaf92c50de"},"outputs":[{"name":"stdout","output_type":"stream","text":["finished 0 user\n","finished 500 user\n","finished 1000 user\n","finished 1500 user\n","finished 2000 user\n","finished 2500 user\n"]}],"source":["item_0_prices, item_1_prices, expected_revenues = [], [], []\n","max_iter = 100\n","lr = 0.01\n","# early_stopping = 3\n","\n","for k in range(len(X_test)): \n","  # setup initial prices (median)\n","  price0 = train_pricing_decisions.price_item_0.median()\n","  price1 = train_pricing_decisions.price_item_1.median()\n","  for num_iter in range(max_iter):\n","    curr_revenue = get_curr_revenue(price0, price1, X_test.iloc[k].copy())\n","    min0, max0 = price0 - lr, price0 + lr\n","    min1, max1 = price1 - lr, price1 + lr\n","    # use p0 +/- lr, and p1 +/- lr to calculate the combination {p0, p1} that gives the max revenue\n","    gradient_0, gradient_1, gradient_revenue = get_gradient_direction(min0, max0, min1, max1, X_test.iloc[k].copy())\n","  \n","    # if the max revenue from the new {p0, p1} combination is smaller than curr revenue -> curr price for item0 and item1 is maximum\n","    if gradient_revenue < curr_revenue:\n","      break\n","    # else we move to the direction of gradient\n","    price0 = gradient_0\n","    price1 = gradient_1\n","    curr_revenue = gradient_revenue\n","  item_0_prices.append(price0)\n","  item_1_prices.append(price1)\n","  expected_revenues.append(curr_revenue)\n","  "]}],"metadata":{"colab":{"collapsed_sections":[],"name":"pds_project.ipynb","provenance":[]},"interpreter":{"hash":"dc4567cdde2f26222a4d257fd7c12c74a291fc7c311992e7754b95982bd63dc3"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":0}
