{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "estimate_buyer_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF7ThMIK0EmC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "N_NEIGHBORS = 5\n",
        "DATA_FILEPATH = './data/'\n",
        "MODEL_FILEPATH = './machine_learning_model/'\n",
        "\n",
        "def openpickle(filename):\n",
        "    with open(DATA_FILEPATH + filename, \"rb\") as readfile:\n",
        "        loaded = pickle.load(readfile)\n",
        "    return loaded\n",
        "\n",
        "def dumppickle(var, filename):\n",
        "    pickle.dump(var, open(MODEL_FILEPATH + filename, 'wb'))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Byz7RQtf0Mx-",
        "outputId": "d7cece30-2112-4038-e74e-6451a0eea8c0"
      },
      "source": [
        "# load files\n",
        "train_covariate = openpickle('train_covariate')\n",
        "train_noisy_embedding = openpickle('train_noisy_embedding')\n",
        "test_covariate = openpickle('test_covariate')\n",
        "test_noisy_embedding = openpickle('test_noisy_embedding')\n",
        "\n",
        "existing_train_idx = list(train_noisy_embedding.index)\n",
        "existing_test_idx = list(test_noisy_embedding.index)\n",
        "\n",
        "existing_covariate = pd.concat([train_covariate.loc[existing_train_idx], test_covariate.loc[existing_test_idx]])\n",
        "\n",
        "train_noisy_embedding.columns = train_noisy_embedding.columns.astype(str)\n",
        "existing_embedding = pd.concat([train_noisy_embedding, test_noisy_embedding], axis=0)\n",
        "\n",
        "# train KNN to get new user vectors\n",
        "neigh = NearestNeighbors(n_neighbors = N_NEIGHBORS)\n",
        "neigh.fit(existing_covariate)\n",
        "\n",
        "#pickle the object and store it in a file\n",
        "existing_embedding.to_pickle(MODEL_FILEPATH + 'existing_embedding')\n",
        "dumppickle(neigh, 'knn_model')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-faf0f4e7578d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_covariate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_covariate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_noisy_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_noisy_embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_covariate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_covariate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_noisy_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_noisy_embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-60bc3e30096c>\u001b[0m in \u001b[0;36mopenpickle\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopenpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_FILEPATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreadfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train_covariate'"
          ]
        }
      ]
    }
  ]
}